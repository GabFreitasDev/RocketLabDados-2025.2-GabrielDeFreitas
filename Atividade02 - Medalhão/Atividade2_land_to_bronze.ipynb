{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8d83256-f30b-4806-8edd-436ea23673b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Notebook1 - Landing -> Bronze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "569e2467-8203-44b6-8231-a5b7220f9817",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1 - Configuração Inicial do Ambiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8fc2d02-f0bd-47a5-a5e1-d627c6844233",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Criar o Catálogo\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS medalhao\")\n",
    "spark.sql(f\"USE CATALOG medalhao\")\n",
    "\n",
    "# Criar os Schemas/Databases para as Camadas\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS bronze\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS silver\")\n",
    "\n",
    "# Criar o Volume\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS default.landing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af36209e-8f1c-4914-8f7f-60a9dec80ddd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Define os nomes dos databases que serão usados\n",
    "- Cria os databases bronze e silver se não existirem\n",
    "- Usa o catalogo \"medalhao\" criado contendo todos os níveis(bronze, silver e gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "878e862f-5d93-4501-8121-1a06f73149b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2 - Função de Ingestão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d023ae9c-9f6f-4f55-be98-eb40690318dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# catalogo = \"medalhao\"\n",
    "# bronze_db_name = \"bronze\" \n",
    "\n",
    "def ingest_csv(nome_arquivo_csv, nome_tabela_bronze):\n",
    "    try:\n",
    "        landing_path = f\"/Volumes/medalhao/default/landing/{nome_arquivo_csv}\"\n",
    "        \n",
    "        # Leitura do arquivo CSV\n",
    "        df = spark.read.csv(landing_path, header=True, inferSchema=True)\n",
    "        \n",
    "        # Verifica se o arquivo não está vazio\n",
    "        if df.count() == 0:\n",
    "            raise ValueError(f\"O arquivo {nome_arquivo_csv} está vazio.\")\n",
    "\n",
    "        # Adiciona a coluna 'ingestion_timestamp' com o timestamp atual\n",
    "        df_with_metadata = df.withColumn(\"ingestion_timestamp\", F.current_timestamp())\n",
    "\n",
    "        # Escrita no formato Delta, sobrescrevendo se já existir\n",
    "        df_with_metadata.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"bronze.{nome_tabela_bronze}\")\n",
    "        \n",
    "        print(f\"Tabela bronze.{nome_tabela_bronze} criada com sucesso a partir de {nome_arquivo_csv}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {nome_arquivo_csv}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec6a62e6-8a2b-4858-82a5-16317ebb6f1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- A função pode ser usada para a ingestão de todos os 9 arquivos CSV\n",
    "- Verificação se o arquivo escolhido não está vazio\n",
    "- Adição da coluna ingestion_timestamp\n",
    "- Passagem para o formato Delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c31dbf0-8b0d-4f01-b267-1986c5ca1374",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3 - Ingestão de Cada um dos 9 arquivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21c42f94-6276-4674-9ca4-5e5b8bb0b886",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Mapeamento: Arquivo CSV -> Tabela Bronze\n",
    "arquivos_e_tabelas = {\n",
    "    \"olist_customers_dataset.csv\": \"ft_consumidores\",\n",
    "    \"olist_geolocation_dataset.csv\": \"ft_geolocalizacao\",\n",
    "    \"olist_order_items_dataset.csv\": \"ft_itens_pedidos\",\n",
    "    \"olist_order_payments_dataset.csv\": \"ft_pagamentos_pedidos\",\n",
    "    \"olist_order_reviews_dataset.csv\": \"ft_avaliacoes_pedidos\",\n",
    "    \"olist_orders_dataset.csv\": \"ft_pedidos\",\n",
    "    \"olist_products_dataset.csv\": \"ft_produtos\",\n",
    "    \"olist_sellers_dataset.csv\": \"ft_vendedores\",\n",
    "    \"product_category_name_translation.csv\": \"dm_categoria_produtos_traducao\"\n",
    "}\n",
    "\n",
    "# Execução da ingestão para todas as tabelas\n",
    "for arquivo, tabela in arquivos_e_tabelas.items():\n",
    "    ingest_csv(arquivo, tabela)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6f46894-4229-42bc-a0ed-3b17b740d008",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- O dicionário liga os arquivos CSV com os nomes das respectivas tabelas\n",
    "- Loop para ingestão sequencial de todas as 9 tabelas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6987f35e-9954-4396-9438-28b3d6dc61e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4 - Função para Ingerir Cotação do Dolar via API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59a86ab2-4571-427c-b5e1-b0cf1b46a9d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def ingest_cotacao_dolar(data_inicio_formatada, data_fim_formatada):\n",
    "    # data_inicio_formatada no formato 'MM-DD-AAAA'\n",
    "    # data_fim_formatada no formato 'MM-DD-AAAA'\n",
    "    try:\n",
    "        print(f\"Ingerindo cotação dólar de {data_inicio_formatada} até {data_fim_formatada}\")\n",
    "        \n",
    "        #URL da API\n",
    "        url_api = (f\"https://olinda.bcb.gov.br/olinda/servico/PTAX/versao/v1/odata/\"\n",
    "                  f\"CotacaoDolarPeriodo(dataInicial=@dataInicial,dataFinalCotacao=@dataFinalCotacao)\"\n",
    "                  f\"?@dataInicial='{data_inicio_formatada}'&@dataFinalCotacao='{data_fim_formatada}'\"\n",
    "                  f\"&$select=dataHoraCotacao,cotacaoCompra,cotacaoVenda&$format=json\")\n",
    "        \n",
    "        print(f\"Período: {data_inicio_formatada} a {data_fim_formatada}\")\n",
    "        \n",
    "        # Requisição à API\n",
    "        response = requests.get(url_api, timeout=30)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            raise ValueError(f\"Erro na API: Status {response.status_code} - {response.text}\")\n",
    "        \n",
    "        dados = response.json()\n",
    "        \n",
    "        # Extrai lista de cotações\n",
    "        cotacoes = dados.get('value', [])\n",
    "        \n",
    "        if not cotacoes:\n",
    "            print(\"Nenhuma cotação encontrada no período\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"{len(cotacoes)} cotações recuperadas\")\n",
    "        \n",
    "        # Mostra amostra dos dados\n",
    "        if len(cotacoes) > 0:\n",
    "            primeira_cotacao = cotacoes[0]\n",
    "            print(f\"Primeira cotação: {primeira_cotacao.get('dataHoraCotacao')} - R$ {primeira_cotacao.get('cotacaoCompra')}\")\n",
    "        \n",
    "        # Converte para DataFrame Spark\n",
    "        df_cotacoes = spark.createDataFrame(cotacoes)\n",
    "        \n",
    "        # Adiciona metadados\n",
    "        df_cotacoes_com_metadados = (df_cotacoes\n",
    "            .withColumn(\"ingestion_timestamp\", F.current_timestamp())\n",
    "            .withColumn(\"data_inicio_periodo\", F.lit(data_inicio_formatada))\n",
    "            .withColumn(\"data_fim_formatada_periodo\", F.lit(data_fim_formatada))\n",
    "        )\n",
    "        \n",
    "        # Mostra schema dos dados\n",
    "        print(\"Schema da cotação:\")\n",
    "        df_cotacoes_com_metadados.printSchema()\n",
    "        \n",
    "        # Salva como tabela Delta\n",
    "        (df_cotacoes_com_metadados\n",
    "         .write\n",
    "         .format(\"delta\")\n",
    "         .mode(\"overwrite\")\n",
    "         .saveAsTable(f\"medalhao.bronze.dm_cotacao_dolar\")\n",
    "        )\n",
    "        \n",
    "        print(f\"bronze.dm_cotacao_dolar criada com {df_cotacoes_com_metadados.count():,} registros\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro na cotação dólar: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Parâmetros podem ser alterados facilmente\n",
    "data_inicio_formatada = \"01-01-2016\" # Primeira data do dataset\n",
    "data_fim_formatada = \"11-09-2025\" # Data a qual eu fiz o código(aparentemente o dataset só vai até 2019)\n",
    "\n",
    "print(f\"Período da cotação: {data_inicio_formatada} a {data_fim_formatada}\")\n",
    "\n",
    "# Executa ingestão da cotação\n",
    "ingestao_cotacao = ingest_cotacao_dolar(data_inicio_formatada, data_fim_formatada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6893393-5019-42fa-ae45-73484ed4651a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- A função realiza a consulta das cotações do dolar atravéz do endpoit da API do Banco Central\n",
    "- As datas passadas como parâmetros da função seguem a formatação de MM/DD/AAAA\n",
    "- Validação dos status da resposta e dados vazios\n",
    "- Estrutura similar as outras tabelas criadas na camada bronze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a5e38ad-0239-4f18-9769-9405f0a9ca4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5 - Validação Final da Camada Bronze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5078dd3-4dab-4b9d-949b-9ea267ada3c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Lista todas as tabelas criadas no database bronze\n",
    "tabelas_bronze = spark.sql(\"SHOW TABLES IN bronze\")\n",
    "tabelas_criadas = [row.tableName for row in tabelas_bronze.collect()]\n",
    "\n",
    "print(f\"Total de tabelas na Bronze: {len(tabelas_criadas)}\")\n",
    "\n",
    "for tabela in tabelas_criadas:\n",
    "    # Conta registros em cada tabela\n",
    "    contagem = spark.sql(f\"SELECT COUNT(*) as total FROM bronze.{tabela}\").collect()[0]['total']\n",
    "    \n",
    "    # Verifica se tem coluna de ingestion_timestamp\n",
    "    colunas = spark.sql(f\"DESCRIBE bronze.{tabela}\")\n",
    "    tem_timestamp = any(\"ingestion_timestamp\" in row.col_name for row in colunas.collect())\n",
    "    \n",
    "    status_timestamp = \"Yes\" if tem_timestamp else \"No\"\n",
    "    \n",
    "    print(f\"{status_timestamp}, {tabela}: {contagem:,} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5aa360b5-fd94-4784-93eb-36af7bcf15ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Conta se possuem 10 tabelas na camada bronze, sendo as 9 importadas e 1 com as cotações do dólar\n",
    "- Verifica a existencia da tabela 'ingestion_timestamp' em todas as tabelas da camada bronze"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Atividade2_land_to_bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
